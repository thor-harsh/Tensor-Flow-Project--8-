{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlBiwATdr0W_"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "xViCBgb1sC6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FbbHJeDBsIRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "    !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "else:\n",
        "    print(\"[INFO] 'helper_functions.py' already exists, skipping download.\")"
      ],
      "metadata": {
        "id": "MOao88KYsmZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "Wkrqytg-te6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "#TFDS stands for tensorflow datasets"
      ],
      "metadata": {
        "id": "QoSqZL_XtfTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_lists=tfds.list_builders()   # list all the datasets\n",
        "print(\"food101\" in dataset_lists)"
      ],
      "metadata": {
        "id": "2SCOp38ZuJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data,test_data),ds_info=tfds.load(name='food101',\n",
        "                                         split=['train','validation'],\n",
        "                                         shuffle_files=True,\n",
        "                                         as_supervised=True,\n",
        "                                         with_info=True)\n",
        "\n",
        "\n",
        "#with_info means to Download the metadata also -> This is the ds_info\n",
        "#shuffle_files state that files needs to shuffled during loading\n",
        "#as_supervised means that the we will get data in form of tuples (data,label)"
      ],
      "metadata": {
        "id": "zwCuYh4Vua6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_info.features"
      ],
      "metadata": {
        "id": "EpOIMK3yvrov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=df_info.features['label'].class_name\n",
        "class_names"
      ],
      "metadata": {
        "id": "--VuC-0axV6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "take_one_sample=train_data.take(1)"
      ],
      "metadata": {
        "id": "O6JCVMSzyEiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image,label in take_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape},\n",
        "  Image dtype: {image.dtype},\n",
        "  Target_class from label: {label},\n",
        "  Class name (str_form): {class_names[label.numpy()]}\n",
        "        \"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rEY3j1y7ytCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reduce_min(image),tf.reduce_max(image)"
      ],
      "metadata": {
        "id": "A7zvXy2MzmgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To verify the label is associated with right image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label.numpy()])\n",
        "\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "N0x-q1Lzz1ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks perform the best when data is in a certain way.(batched, normalized)\n",
        "\n",
        "#However, not all data(including  data from tensorflow datasets comes like this)\n",
        "\n",
        "\n",
        "\n",
        "#Since we are going to be using EfficientNetBX pretrained model then we don't need to rescale the data. These architectures have rescaling built in"
      ],
      "metadata": {
        "id": "IaXQDeu61cC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img(image,label,img_shape=224):\n",
        "  img=tf.image.resize(image,[img_shape,img_shape])\n",
        "  img=img/255.\n",
        "  return tf.cast(img,tf.float32),label"
      ],
      "metadata": {
        "id": "-RXRTPFV2sGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_img(image,label)"
      ],
      "metadata": {
        "id": "wu_Rm6903c4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Batch and Prepare Datasets"
      ],
      "metadata": {
        "id": "i89Bas6f49MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.map(map_func=preprocess_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_data=train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_data=test_data.map(map_func=preprocess_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_data=test_data.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "LzycnPFw6CSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data"
      ],
      "metadata": {
        "id": "KPurnQCX-ga1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "checkpoint_path=\"model_checkpoints/cp.ckpt\"\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                       save_weights_only=True,\n",
        "                                                       save_best_only=True,\n",
        "                                                       monitor='val_accuracy',\n",
        "                                                       verbose=0)\n",
        "\n",
        "checkpoint_callback"
      ],
      "metadata": {
        "id": "xoGRH1di-iP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tensorboard callbacks- to log training results\n",
        "###ModelCheckpoint callbacks- To save our model's progress after feature_extraction"
      ],
      "metadata": {
        "id": "i-0NSWtd_PtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixed precision utilizes the combination of float16 and float32 data types to increase the model_performance"
      ],
      "metadata": {
        "id": "ArDvZzCK_bI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "yvo5OdLHBMFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "id": "VZ64ZYRdCS1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Activation"
      ],
      "metadata": {
        "id": "tirExdiADtTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "input_shape=(224,224,3)\n",
        "base_model=tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable=False\n",
        "\n",
        "inputs=layers.Input(shape=input_shape,name='input_layer')\n",
        "x=base_model(inputs,training=False)\n",
        "x=layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "x=layers.Dense(len(class_names))(x) # output layers\n",
        "outputs=layers.Activation('softmax',dtype=tf.float32,name='softmax_float32')(x)\n",
        "\n",
        "model=tf.keras.Model(inputs,outputs)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "DxMtsDV8CWkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Eecgri-AECrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in model.layers:\n",
        "  print(layer.name,layer.trainable,layer.dtype,layer,dtype_policy)"
      ],
      "metadata": {
        "id": "icm-b47nEGQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[1].layers[:20]:\n",
        "  print(layer.name,layer.trainable,layer.dtype,layer.dtype_policy)"
      ],
      "metadata": {
        "id": "PVsD_li9Eb_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "history_101_food_classes_feature_extract=model.fit(train_data,\n",
        "                                                   epochs=3,\n",
        "                                                   steps_per_epoch=len(train_data),\n",
        "                                                   validation_steps=int(0.15*len(test_data)),\n",
        "                                                   validation_data=test_data,\n",
        "                                                   callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                                                          experiment_name='efficientnetb0_101_classes_all_data_feature_extract'),\n",
        "                                                              checkpoint_callback])"
      ],
      "metadata": {
        "id": "xPJcb5bzEpfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model (unsaved version) on whole test dataset\n",
        "results_feature_extract_model = model.evaluate(test_data)\n",
        "results_feature_extract_model"
      ],
      "metadata": {
        "id": "mi_2namNJFjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a function to recreate the original model\n",
        "def create_model():\n",
        "  # Create base model\n",
        "  input_shape = (224, 224, 3)\n",
        "  base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\n",
        "  base_model.trainable = False # freeze base model layers\n",
        "\n",
        "  # Create Functional model\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "  # Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "  # x = layers.Rescaling(1./255)(x)\n",
        "  x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "  x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "  x = layers.Dense(len(class_names))(x) # want one output neuron per class\n",
        "  # Separate activation of output layer so we can output float32 activations\n",
        "  outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Qe7ZUso-Kw6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create and compile a new version of the original model (new weights)\n",
        "created_model = create_model()\n",
        "\n",
        "\n",
        "# 3. Load the saved weights\n",
        "created_model.load_weights(checkpoint_path)\n",
        "\n",
        "created_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=[\"accuracy\"])\n",
        "\n",
        "# 4. Evaluate the model with loaded weights\n",
        "results_created_model_with_loaded_weights = created_model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "C67J-nQzLKYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model locally (if you're using Google Colab, your saved model will Colab instance terminates)\n",
        "save_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\n",
        "model.save(save_dir)"
      ],
      "metadata": {
        "id": "nPZXJFLQLK_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_saved_model = tf.keras.models.load_model(save_dir)"
      ],
      "metadata": {
        "id": "B0OLPCzUL03w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_loaded_saved_model = loaded_saved_model.evaluate(test_data)\n",
        "results_loaded_saved_model"
      ],
      "metadata": {
        "id": "XtSODRuJL3B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"
      ],
      "metadata": {
        "id": "ybBhDW_lMETh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n",
        "!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"
      ],
      "metadata": {
        "id": "wCOYCqCnMEhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model=tf.keras.models.load_model(\"downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"
      ],
      "metadata": {
        "id": "zV6Njx3KMQLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.summary()"
      ],
      "metadata": {
        "id": "E2acBF9OMahw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                                               patience=3)\n",
        "\n",
        "checkpoint_path = \"fine_tune_checkpoints/\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "QdPKKin0Mbh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                               factor=0.2,\n",
        "                                               patience=2,\n",
        "                                               verbose=1,\n",
        "                                               min_lr=1e-7)"
      ],
      "metadata": {
        "id": "ZjsXp9cHNU5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                        metrics=['accuracy'])\n",
        "history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(train_data,\n",
        "                                                        epochs=100, # fine-tune for a maximum of 100 epochs\n",
        "                                                        steps_per_epoch=len(train_data),\n",
        "                                                        validation_data=test_data,\n",
        "                                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n",
        "                                                        callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # track the model training logs\n",
        "                                                                   model_checkpoint, # save only the best model during training\n",
        "                                                                   early_stopping, # stop model after X epochs of no improvements\n",
        "                                                                   reduce_lr])"
      ],
      "metadata": {
        "id": "ZHLcqc9ANnbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.evaluate(test_data)\n"
      ],
      "metadata": {
        "id": "3jehGEjwOThW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_gs_model.save(\"ANy path of your choice\")"
      ],
      "metadata": {
        "id": "-9Eyqa3LOXw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./ \\\n",
        "--name \\\n",
        "--description \\\n",
        "--one_shot"
      ],
      "metadata": {
        "id": "bE6clyHAOZV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "EVFXfwSBO09I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard delete experiment_id \"/\""
      ],
      "metadata": {
        "id": "SE_sc4pbO3LU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}